package org.apache.mahout.clustering.elkan;

import static org.apache.mahout.clustering.iterator.ClusterIterator.PRIOR_PATH_KEY;

import java.io.IOException;
import java.util.ArrayList;
import java.util.Iterator;
import java.util.List;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileStatus;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.fs.PathFilter;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.io.WritableComparable;
import org.apache.hadoop.mapred.JobConf;
import org.apache.hadoop.mapred.lib.MultipleOutputFormat;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.Reducer;
import org.apache.hadoop.mapreduce.Mapper.Context;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
import org.apache.hadoop.mapreduce.lib.output.MultipleOutputs;
import org.apache.hadoop.mapreduce.lib.output.SequenceFileOutputFormat;
import org.apache.mahout.clustering.Cluster;
import org.apache.mahout.clustering.classify.ClusterClassifier;
import org.apache.mahout.clustering.elkan.ElkanClusterDistanceStepJob.ElkanClusterDistanceMapper;
import org.apache.mahout.clustering.iterator.ClusterIterator;
import org.apache.mahout.clustering.iterator.ClusterWritable;
import org.apache.mahout.clustering.iterator.ClusteringPolicy;
import org.apache.mahout.common.distance.DistanceMeasure;
import org.apache.mahout.common.iterator.sequencefile.PathFilters;
import org.apache.mahout.common.iterator.sequencefile.SequenceFileValueIterator;
import org.apache.mahout.math.Vector;
import org.apache.mahout.math.VectorWritable;
import org.apache.mahout.math.Vector.Element;
import org.apache.mahout.math.map.OpenHashMap;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import com.google.common.io.Closeables;

public class ElkanIterator {
	public static final String NEW_PRIOR_PATH_KEY = "org.apache.mahout.clustering.prior.path_new";
	public static final String CENTROID_DISTANCES_PATH_KEY = "org.apache.mahout.clustering.centroid.distances.path_new";
	public static final String ITERATION_KEY = "org.apache.mahout.clustering.iteration";
	private static final Logger log = LoggerFactory
			.getLogger(ElkanDriver.class);

	public void iterateTest(Configuration conf, Path inPath, Path priorPath,
			Path outPath, int numIterations) throws IOException,
			InterruptedException, ClassNotFoundException {
		ClusteringPolicy policy = ClusterClassifier.readPolicy(priorPath);
		Path clustersOut = null;
		int iteration = 1;
		while (iteration <= numIterations) {
			conf.set(PRIOR_PATH_KEY, priorPath.toString());
			conf.set("iteration", iteration+"");
			Job job = new Job(conf, "Test job.");

			job.setMapperClass(TestMapper.class);
			job.setMapOutputKeyClass(IntWritable.class);
			job.setMapOutputValueClass(ClusterWritable.class);

			job.setReducerClass(TestReducer.class);
			job.setOutputKeyClass(IntWritable.class);
			job.setOutputValueClass(ClusterWritable.class);

			job.setInputFormatClass(SequenceFileInputFormat.class);
			job.setOutputFormatClass(SequenceFileOutputFormat.class);

			clustersOut = new Path(outPath, Cluster.CLUSTERS_DIR + 1);
			priorPath = clustersOut;
			FileOutputFormat.setOutputPath(job, clustersOut);

			FileInputFormat.addInputPath(job, inPath);
			if (iteration>1)
			FileInputFormat.setInputPathFilter(job, ElkanVectorFilter.class);
			MultipleOutputs.addNamedOutput(job, "elkanvectors" + iteration,
					SequenceFileOutputFormat.class, Text.class,
					VectorWritable.class);

			job.setJarByClass(ElkanIterator.class);

			if (!job.waitForCompletion(true)) {
				throw new InterruptedException("Cluster Iteration " + iteration
						+ " failed processing " + priorPath);
			}
			ClusterClassifier.writePolicy(policy, clustersOut);
			FileSystem fs = FileSystem.get(outPath.toUri(), conf);
			iteration++;
			if (isConverged(clustersOut, conf, fs)) {
				break;
			}
		}

	}

	public static class ElkanVectorFilter implements PathFilter {

		@Override
		public boolean accept(Path arg0) {
			// TODO Auto-generated method stub
			return false;
		}

	}

	public static class TestMapper
			extends
			Mapper<WritableComparable<?>, VectorWritable, IntWritable, ClusterWritable> {

		private ClusterClassifier classifier;
		private ClusteringPolicy policy;
		private MultipleOutputs<Text, VectorWritable> m_multiOutputs;
		private String elkanVectorOutputKey;

		@Override
		protected void setup(Context context) throws IOException,
				InterruptedException {
			Configuration conf = context.getConfiguration();
			String priorClustersPath = conf.get(ClusterIterator.PRIOR_PATH_KEY);
			classifier = new ClusterClassifier();
			classifier.readFromSeqFiles(conf, new Path(priorClustersPath));
			policy = classifier.getPolicy();
			policy.update(classifier);
			m_multiOutputs = new MultipleOutputs(context);
			elkanVectorOutputKey="elkanvectors"+conf.get("iteration");
			super.setup(context);
		}

		@Override
		protected void map(WritableComparable<?> key, VectorWritable value,
				Context context) throws IOException, InterruptedException {
			Vector probabilities = classifier.classify(value.get());
			Vector selections = policy.select(probabilities);
			for (Iterator<Element> it = selections.iterateNonZero(); it
					.hasNext();) {
				Element el = it.next();
				classifier.train(el.index(), value.get(), el.get());
			}
			m_multiOutputs.write(elkanVectorOutputKey, key, value);
		}

		@Override
		protected void cleanup(Context context) throws IOException,
				InterruptedException {
			List<Cluster> clusters = classifier.getModels();
			ClusterWritable cw = new ClusterWritable();
			for (int index = 0; index < clusters.size(); index++) {
				cw.setValue(clusters.get(index));
				context.write(new IntWritable(index), cw);
			}
			m_multiOutputs.close();
			super.cleanup(context);
		}
	}

	public static class TestReducer extends
			Reducer<IntWritable, ClusterWritable, IntWritable, ClusterWritable> {
		private ClusterClassifier classifier;
		private ClusteringPolicy policy;

		@Override
		protected void reduce(IntWritable key,
				Iterable<ClusterWritable> values, Context context)
				throws IOException, InterruptedException {
			Iterator<ClusterWritable> iter = values.iterator();
			Cluster first = iter.next().getValue(); // there must always be at
													// least one
			while (iter.hasNext()) {
				Cluster cluster = iter.next().getValue();
				first.observe(cluster);
			}
			List<Cluster> models = new ArrayList<Cluster>();
			models.add(first);
			classifier = new ClusterClassifier(models, policy);
			classifier.close();
			context.write(key, new ClusterWritable(first));
		}

		@Override
		protected void setup(Context context) throws IOException,
				InterruptedException {
			Configuration conf = context.getConfiguration();
			String priorClustersPath = conf.get(ClusterIterator.PRIOR_PATH_KEY);
			classifier = new ClusterClassifier();
			classifier.readFromSeqFiles(conf, new Path(priorClustersPath));
			policy = classifier.getPolicy();
			policy.update(classifier);
			super.setup(context);
		}
	}

	public void iterateOneMap(Configuration conf, Path inPath, Path priorPath,
			Path outPath, int numIterations) throws IOException,
			InterruptedException, ClassNotFoundException {
		ClusteringPolicy policy = ClusterClassifier.readPolicy(priorPath);
		Path clustersOut = null;
		int iteration = 1;

		conf.set(PRIOR_PATH_KEY, priorPath.toString());
		Path localInPath = new Path(outPath, ElkanClassifier.ELKAN_VECTORS_DIR
				+ ElkanClassifier.ELKAN_STEP_1 + iteration);

		// while (vectors_created==0 && iteration <= numIterations) {
		// log.info("Working on Iteration "+iteration);
		// conf.set(PRIOR_PATH_KEY, priorPath.toString());
		// conf.set(ITERATION_KEY, iteraton+"");
		//
		// iteration++;
		// priorPath = clustersOut;
		// }
		Path finalClustersIn = new Path(outPath, Cluster.CLUSTERS_DIR
				+ (iteration - 1) + Cluster.FINAL_ITERATION_SUFFIX);
		FileSystem.get(clustersOut.toUri(), conf).rename(clustersOut,
				finalClustersIn);
	}

	/**
	 * Iterate over data using a prior-trained ClusterClassifier, for a number
	 * of iterations using a mapreduce implementation
	 * 
	 * @param conf
	 *            the Configuration
	 * @param inPath
	 *            a Path to input VectorWritables
	 * @param priorPath
	 *            a Path to the prior classifier
	 * @param outPath
	 *            a Path of output directory
	 * @param numIterations
	 *            the int number of iterations to perform
	 */
	public void iterateMR(Configuration conf, Path inPath, Path priorPath,
			Path outPath, int numIterations) throws IOException,
			InterruptedException, ClassNotFoundException {
		ClusteringPolicy policy = ClusterClassifier.readPolicy(priorPath);
		Path clustersOut = null;
		int iteration = 1;
		log.info("Creating Elkan Vectors");
		conf.set(PRIOR_PATH_KEY, priorPath.toString());
		Path localInPath = new Path(outPath, ElkanClassifier.ELKAN_VECTORS_DIR
				+ ElkanClassifier.ELKAN_STEP_1 + iteration);
		int vectors_created = ElkanVectorsCreateJob.run(inPath, localInPath,
				conf);
		while (vectors_created == 0 && iteration <= numIterations) {
			log.info("Working on Iteration " + iteration);
			conf.set(PRIOR_PATH_KEY, priorPath.toString());

			log.info("Iteration " + iteration
					+ " - Creating Cluster Distances Matrix");
			Path distanceMatrixPath = new Path(outPath,
					ElkanClassifier.CLUSTER_DISTANCES_DIR + iteration);
			conf.set(CENTROID_DISTANCES_PATH_KEY, distanceMatrixPath.toString());
			ElkanClusterDistanceStepJob
					.run(priorPath, distanceMatrixPath, conf);
			log.info("Iteration " + iteration + " - Elkan Clustering Step 1");
			Path output2 = new Path(outPath, ElkanClassifier.ELKAN_VECTORS_DIR
					+ ElkanClassifier.ELKAN_STEP_2 + iteration);
			ElkanStep1Job.run(localInPath, output2, conf);
			log.info("Iteration " + iteration + " - Elkan Clustering Step 2");
			clustersOut = new Path(outPath, Cluster.CLUSTERS_DIR
					+ (iteration + 1));
			ElkanStep2Job.run(output2, clustersOut, conf);
			ClusterClassifier.writePolicy(policy, clustersOut);
			FileSystem fs = FileSystem.get(outPath.toUri(), conf);
			if (isConverged(clustersOut, conf, fs)) {
				log.info("Elkan Clustering converged");
				break;
			} else {
				log.info("Iteration " + iteration
						+ " - Elkan Clustering Step 3");
				conf.set(NEW_PRIOR_PATH_KEY, clustersOut.toString());
				localInPath = new Path(outPath,
						ElkanClassifier.ELKAN_VECTORS_DIR
								+ ElkanClassifier.ELKAN_STEP_3
								+ (iteration + 1));
				ElkanStep3Job.run(output2, localInPath, conf);
			}

			iteration++;
			priorPath = clustersOut;
		}
		Path finalClustersIn = new Path(outPath, Cluster.CLUSTERS_DIR
				+ (iteration - 1) + Cluster.FINAL_ITERATION_SUFFIX);
		FileSystem.get(clustersOut.toUri(), conf).rename(clustersOut,
				finalClustersIn);
	}

	/**
	 * Return if all of the Clusters in the parts in the filePath have converged
	 * or not
	 * 
	 * @param filePath
	 *            the file path to the single file containing the clusters
	 * @return true if all Clusters are converged
	 * @throws IOException
	 *             if there was an IO error
	 */
	private boolean isConverged(Path filePath, Configuration conf, FileSystem fs)
			throws IOException {
		for (FileStatus part : fs
				.listStatus(filePath, PathFilters.partFilter())) {
			SequenceFileValueIterator<ClusterWritable> iterator = new SequenceFileValueIterator<ClusterWritable>(
					part.getPath(), true, conf);
			while (iterator.hasNext()) {
				ClusterWritable value = iterator.next();
				if (!value.getValue().isConverged()) {
					Closeables.closeQuietly(iterator);
					return false;
				}
			}
		}
		return true;
	}

}
