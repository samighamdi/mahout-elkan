package org.apache.mahout.clustering.elkan;

import java.io.IOException;
import java.util.Iterator;
import java.util.List;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.WritableComparable;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.Mapper.Context;
import org.apache.hadoop.mapreduce.lib.output.MultipleOutputs;
import org.apache.mahout.clustering.Cluster;
import org.apache.mahout.clustering.classify.ClusterClassifier;
import org.apache.mahout.clustering.iterator.ClusterIterator;
import org.apache.mahout.clustering.kmeans.KMeansConfigKeys;
import org.apache.mahout.common.ClassUtils;
import org.apache.mahout.common.distance.DistanceMeasure;
import org.apache.mahout.math.DenseVector;
import org.apache.mahout.math.MatrixSlice;
import org.apache.mahout.math.Vector;
import org.apache.mahout.math.hadoop.DistributedRowMatrix;
import org.apache.mahout.math.map.OpenHashMap;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

public class ElkanVectorUpdateMapper extends
		ElkanMapper<WritableComparable<?>, ElkanVectorWritable> {
	private static final Logger log = LoggerFactory
			.getLogger(ElkanVectorUpdateMapper.class);

	private Vector oldClusterDistances;

	@Override
	protected void setup(Context context) throws IOException,
			InterruptedException {
		Configuration conf = context.getConfiguration();
		int i;
		List<Cluster> models = setupGeneral(context, conf);
		
		String newPriorClustersPath = conf
				.get(ElkanIterator.NEW_PRIOR_PATH_KEY);
		
		ElkanClassifier elkanClassifier = new ElkanClassifier();
		
		List<Cluster> newModels = elkanClassifier.readNewModelsFromSeqFiles(
				conf, new Path(newPriorClustersPath));		
		
		oldClusterDistances = new DenseVector(newModels.size());
		for (i = 0; i < newModels.size(); i++) {
			Vector oldCenter = models.get(i).getCenter();
			Vector newCenter = newModels.get(i).getCenter();
			oldClusterDistances.setQuick(i,
					measure.distance(oldCenter, newCenter));
		}
		super.setup(context);
	}

	private List<Cluster> setupGeneral(Context context, Configuration conf)
			throws IOException {
		String measureClass = conf.get(KMeansConfigKeys.DISTANCE_MEASURE_KEY);
		measure = ClassUtils.instantiateAs(measureClass, DistanceMeasure.class);

		String priorClustersPath = conf.get(ClusterIterator.PRIOR_PATH_KEY);
		classifier = new ClusterClassifier();
		classifier.readFromSeqFiles(conf, new Path(priorClustersPath));
		policy = classifier.getPolicy();
		policy.update(classifier);

		int i = 0;
		List<Cluster> models = classifier.getModels();
		medianDistanceClusters = new DenseVector(models.size());

		for (Cluster model : models) {
			Vector centerDistances = new DenseVector(models.size());
			int j = 0;
			for (Cluster oth_model : models) {
				centerDistances.setQuick(
						j,
						measure.distance(model.getCenter(),
								oth_model.getCenter()));
				j++;
			}

			double sCenter = centerDistances.minValue() / 2;
			medianDistanceClusters.setQuick(i, sCenter);
			i++;
		}

		clusterDistanceMatrix = new OpenHashMap<Integer, Vector>(models.size());
		Path clusterDistanceMatrixPath = new Path(
				conf.get(ElkanIterator.CENTROID_DISTANCES_PATH_KEY));
		Path clusterDistanceMatrixOutput = new Path(
				conf.get(ElkanIterator.CENTROID_DISTANCES_PATH_KEY) + "/output");
		DistributedRowMatrix rowMatrix = new DistributedRowMatrix(
				clusterDistanceMatrixPath, clusterDistanceMatrixOutput,
				models.size(), models.size());
		rowMatrix.setConf(conf);
		Iterator<MatrixSlice> it = rowMatrix.iterator();
		while (it.hasNext()) {
			MatrixSlice slice = it.next();
			clusterDistanceMatrix.put(slice.index(), slice.vector());
		}		

		m_multiOutputs = new MultipleOutputs(context);
		return models;
	}

	@Override
	protected void map(WritableComparable<?> key, ElkanVectorWritable value,
			Context context) throws IOException, InterruptedException {
		ElkanVector elkanVector = value.get();
		ElkanSteps.updateVectorLimits(elkanVector, oldClusterDistances);
		ElkanSteps.updateVectorCentroid(elkanVector, classifier,
				medianDistanceClusters, clusterDistanceMatrix, measure);
		m_multiOutputs.write("elkanVectors", key, elkanVector);
	}
}