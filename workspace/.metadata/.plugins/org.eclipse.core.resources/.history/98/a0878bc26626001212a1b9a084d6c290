package org.apache.mahout.clustering.elkan;

import java.io.IOException;
import java.util.List;

import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.lib.output.MultipleOutputs;
import org.apache.mahout.clustering.Cluster;
import org.apache.mahout.clustering.classify.ClusterClassifier;
import org.apache.mahout.clustering.iterator.ClusterWritable;
import org.apache.mahout.clustering.iterator.ClusteringPolicy;
import org.apache.mahout.common.distance.DistanceMeasure;
import org.apache.mahout.math.Vector;
import org.apache.mahout.math.VectorWritable;
import org.apache.mahout.math.map.OpenHashMap;

public abstract class ElkanMapper<KEYIN,VALUEIN> extends 
	Mapper<KEYIN,VALUEIN,IntWritable,ClusterWritable> {

	protected ClusterClassifier classifier;
	protected ClusteringPolicy policy;
	protected Vector medianDistanceClusters;
	protected DistanceMeasure measure;
	protected OpenHashMap<Integer, Vector> clusterDistanceMatrix;
	protected MultipleOutputs<Text, VectorWritable> m_multiOutputs;

	@Override
	protected void cleanup(org.apache.hadoop.mapreduce.Mapper.Context context) throws IOException,
			InterruptedException {
				List<Cluster> clusters = classifier.getModels();
				ClusterWritable cw = new ClusterWritable();
				for (int index = 0; index < clusters.size(); index++) {
					cw.setValue(clusters.get(index));
					context.write(new IntWritable(index), cw);
				}
				super.cleanup(context);
			}
	
	

}
