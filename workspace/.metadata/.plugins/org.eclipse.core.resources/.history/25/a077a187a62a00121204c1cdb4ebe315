/* Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.mahout.clustering.elkan;

import static org.apache.mahout.clustering.topdown.PathDirectory.CLUSTERED_POINTS_DIRECTORY;

import java.io.IOException;
import java.util.ArrayList;
import java.util.List;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.util.ToolRunner;
import org.apache.mahout.clustering.Cluster;
import org.apache.mahout.clustering.classify.ClusterClassificationDriver;
import org.apache.mahout.clustering.classify.ClusterClassifier;
import org.apache.mahout.clustering.iterator.ClusterIterator;
import org.apache.mahout.clustering.iterator.ClusteringPolicy;
import org.apache.mahout.clustering.iterator.KMeansClusteringPolicy;
import org.apache.mahout.clustering.kmeans.KMeansConfigKeys;
import org.apache.mahout.clustering.kmeans.RandomSeedGenerator;
import org.apache.mahout.common.AbstractJob;
import org.apache.mahout.common.ClassUtils;
import org.apache.mahout.common.HadoopUtil;
import org.apache.mahout.common.commandline.DefaultOptionCreator;
import org.apache.mahout.common.distance.DistanceMeasure;
import org.apache.mahout.common.distance.SquaredEuclideanDistanceMeasure;
import org.apache.mahout.math.VectorWritable;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

public class ElkanDriver extends AbstractJob {

	private static final Logger log = LoggerFactory
			.getLogger(ElkanDriver.class);

	public static void main(String[] args) throws Exception {
		ToolRunner.run(new Configuration(), new ElkanDriver(), args);
	}

	@Override
	public int run(String[] args) throws Exception {

		addInputOption();
		addOutputOption();
		addOption(DefaultOptionCreator.distanceMeasureOption().create());
		addOption(DefaultOptionCreator
				.clustersInOption()
				.withDescription(
						"The input centroids, as Vectors.  Must be a SequenceFile of Writable, Cluster/Canopy.  "
								+ "If genClusters is also specified, then a random set of vectors will be selected"
								+ " and written out to this path first")
				.create());
		addOption(ElkanOptionCreator
				.numClustersOption()
				.withDescription(
						"The k in Elkan k-Means. It is required in order to create a matrix of cluster distances. You can specify genClusters option to reuse an existing clusters dataset")
				.create());
		addOption(ElkanOptionCreator
				.useNamedVectors().create());
		addOption(ElkanOptionCreator.generateClusters().create());
		addOption(DefaultOptionCreator.convergenceOption().create());
		addOption(DefaultOptionCreator.maxIterationsOption().create());
		addOption(DefaultOptionCreator.overwriteOption().create());
		addOption(DefaultOptionCreator.clusteringOption().create());
		addOption(DefaultOptionCreator.methodOption().create());
		addOption(DefaultOptionCreator.outlierThresholdOption().create());

		if (parseArguments(args) == null) {
			return -1;
		}

		Path input = getInputPath();
		Path clusters = new Path(
				getOption(DefaultOptionCreator.CLUSTERS_IN_OPTION));
		Path output = getOutputPath();
		String measureClass = getOption(DefaultOptionCreator.DISTANCE_MEASURE_OPTION);
		if (measureClass == null) {
			measureClass = SquaredEuclideanDistanceMeasure.class.getName();
		}
		double convergenceDelta = Double
				.parseDouble(getOption(DefaultOptionCreator.CONVERGENCE_DELTA_OPTION));
		int maxIterations = Integer
				.parseInt(getOption(DefaultOptionCreator.MAX_ITERATIONS_OPTION));
		if (hasOption(DefaultOptionCreator.OVERWRITE_OPTION)) {
			HadoopUtil.delete(getConf(), output);
		}
		DistanceMeasure measure = ClassUtils.instantiateAs(measureClass,
				DistanceMeasure.class);
		
		int numClusters=Integer.parseInt(getOption(DefaultOptionCreator.NUM_CLUSTERS_OPTION));

		if (hasOption(ElkanOptionCreator.GENERATE_CLUSTERS_OPTION)) {
			clusters = RandomSeedGenerator
					.buildRandom(getConf(),	input, clusters,numClusters,measure);
		}
		boolean namedVectors = hasOption(ElkanOptionCreator.NAMED_VECTORS_OPTION);
		boolean runClustering = hasOption(DefaultOptionCreator.CLUSTERING_OPTION);
		boolean runSequential = getOption(DefaultOptionCreator.METHOD_OPTION)
				.equalsIgnoreCase(DefaultOptionCreator.SEQUENTIAL_METHOD);
		if (getConf() == null) {
			setConf(new Configuration());
		}
		double clusterClassificationThreshold = 0.0;
		if (hasOption(DefaultOptionCreator.OUTLIER_THRESHOLD)) {
			clusterClassificationThreshold = Double
					.parseDouble(getOption(DefaultOptionCreator.OUTLIER_THRESHOLD));
		}
		run(getConf(), input, clusters, output, measure, convergenceDelta,
				maxIterations, runClustering, clusterClassificationThreshold,
				runSequential,numClusters, namedVectors);
		return 0;
	}

	/**
	 * Iterate over the input vectors to produce clusters and, if requested, use
	 * the results of the final iteration to cluster the input vectors.
	 * 
	 * @param input
	 *            the directory pathname for input points
	 * @param clustersIn
	 *            the directory pathname for initial & computed clusters
	 * @param output
	 *            the directory pathname for output points
	 * @param measure
	 *            the DistanceMeasure to use
	 * @param convergenceDelta
	 *            the convergence delta value
	 * @param maxIterations
	 *            the maximum number of iterations
	 * @param runClustering
	 *            true if points are to be clustered after iterations are
	 *            completed
	 * @param clusterClassificationThreshold
	 *            Is a clustering strictness / outlier removal parameter. Its
	 *            value should be between 0 and 1. Vectors having pdf below this
	 *            value will not be clustered.
	 * @param runSequential
	 *            if true execute sequential algorithm
	 */
	public static void run(Configuration conf, Path input, Path clustersIn,
			Path output, DistanceMeasure measure, double convergenceDelta,
			int maxIterations, boolean runClustering,
			double clusterClassificationThreshold, boolean runSequential, int numClusters, boolean namedVectors)
			throws IOException, InterruptedException, ClassNotFoundException {

		// iterate until the clusters converge
		String delta = Double.toString(convergenceDelta);
		if (log.isInfoEnabled()) {
			log.info("Input: {} Clusters In: {} Out: {} Distance: {}",
					new Object[] { input, clustersIn, output,
							measure.getClass().getName() });
			log.info(
					"convergence: {} max Iterations: {} num Reduce Tasks: {} Input Vectors: {}",
					new Object[] { convergenceDelta, maxIterations,
							VectorWritable.class.getName() });
		}
		Path clustersOut = buildClusters(conf, input, clustersIn, output,
				measure, maxIterations, delta, runSequential, numClusters);
		if (runClustering) {
			log.info("Clustering data");
			clusterData(conf, input, clustersOut, output, measure,
					clusterClassificationThreshold, runSequential);
		}
	}

	/**
	 * Iterate over the input vectors to produce clusters and, if requested, use
	 * the results of the final iteration to cluster the input vectors.
	 * 
	 * @param input
	 *            the directory pathname for input points
	 * @param clustersIn
	 *            the directory pathname for initial & computed clusters
	 * @param output
	 *            the directory pathname for output points
	 * @param measure
	 *            the DistanceMeasure to use
	 * @param convergenceDelta
	 *            the convergence delta value
	 * @param maxIterations
	 *            the maximum number of iterations
	 * @param runClustering
	 *            true if points are to be clustered after iterations are
	 *            completed
	 * @param clusterClassificationThreshold
	 *            Is a clustering strictness / outlier removal parrameter. Its
	 *            value should be between 0 and 1. Vectors having pdf below this
	 *            value will not be clustered.
	 * @param runSequential
	 *            if true execute sequential algorithm
	 */
	public static void run(Path input, Path clustersIn, Path output,
			DistanceMeasure measure, double convergenceDelta,
			int maxIterations, boolean runClustering,
			double clusterClassificationThreshold, boolean runSequential, int numClusters)
			throws IOException, InterruptedException, ClassNotFoundException {
		run(new Configuration(), input, clustersIn, output, measure,
				convergenceDelta, maxIterations, runClustering,
				clusterClassificationThreshold, runSequential,numClusters);
	}

	/**
	 * Iterate over the input vectors to produce cluster directories for each
	 * iteration
	 * 
	 * @param conf
	 *            the Configuration to use
	 * @param input
	 *            the directory pathname for input points
	 * @param clustersIn
	 *            the directory pathname for initial & computed clusters
	 * @param output
	 *            the directory pathname for output points
	 * @param measure
	 *            the classname of the DistanceMeasure
	 * @param maxIterations
	 *            the maximum number of iterations
	 * @param delta
	 *            the convergence delta value
	 * @param runSequential
	 *            if true execute sequential algorithm
	 * @param numClusters 
	 * 
	 * @return the Path of the final clusters directory
	 */
	public static Path buildClusters(Configuration conf, Path input,
			Path clustersIn, Path output, DistanceMeasure measure,
			int maxIterations, String delta, boolean runSequential, int numClusters, namedVectors)
			throws IOException, InterruptedException, ClassNotFoundException {

		double convergenceDelta = Double.parseDouble(delta);
		List<Cluster> clusters = new ArrayList<Cluster>();
		ElkanUtil.configureWithClusterInfo(conf, clustersIn, clusters);
		conf.set(KMeansConfigKeys.DISTANCE_MEASURE_KEY, measure.getClass()
		        .getName());
		if (clusters.isEmpty()) {
			throw new IllegalStateException("No input clusters found in "
					+ clustersIn + ". Check your -c argument.");
		}

		Path priorClustersPath = new Path(output, Cluster.INITIAL_CLUSTERS_DIR);
		ClusteringPolicy policy = new KMeansClusteringPolicy(convergenceDelta);
		ClusterClassifier prior = new ClusterClassifier(clusters, policy);
		prior.writeToSeqFiles(priorClustersPath);
		
		if (runSequential) {
			//new ClusterIterator().iterateSeq(conf, input, priorClustersPath,
			//		output, maxIterations);
		} else {
			new ElkanIterator().iterateMR(conf, input, priorClustersPath,
					output, maxIterations, measure,numClusters);
		}
		return output;
	}

	/**
	 * Run the job using supplied arguments
	 * 
	 * @param input
	 *            the directory pathname for input points
	 * @param clustersIn
	 *            the directory pathname for input clusters
	 * @param output
	 *            the directory pathname for output points
	 * @param measure
	 *            the classname of the DistanceMeasure
	 * @param clusterClassificationThreshold
	 *            Is a clustering strictness / outlier removal parrameter. Its
	 *            value should be between 0 and 1. Vectors having pdf below this
	 *            value will not be clustered.
	 * @param runSequential
	 *            if true execute sequential algorithm
	 */
	public static void clusterData(Configuration conf, Path input,
			Path clustersIn, Path output, DistanceMeasure measure,
			double clusterClassificationThreshold, boolean runSequential)
			throws IOException, InterruptedException, ClassNotFoundException {

		if (log.isInfoEnabled()) {
			log.info("Running Clustering");
			log.info("Input: {} Clusters In: {} Out: {} Distance: {}",
					new Object[] { input, clustersIn, output, measure });
		}
		ClusterClassifier.writePolicy(new KMeansClusteringPolicy(), clustersIn);
		ClusterClassificationDriver.run(input, output, new Path(output,
				CLUSTERED_POINTS_DIRECTORY), clusterClassificationThreshold,
				true, runSequential);
	}
}
