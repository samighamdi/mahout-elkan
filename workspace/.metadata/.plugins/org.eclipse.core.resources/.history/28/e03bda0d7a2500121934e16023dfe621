package org.apache.mahout.clustering.elkan;

import java.io.IOException;
import java.util.Iterator;
import java.util.List;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.io.WritableComparable;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.Reducer;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
import org.apache.hadoop.mapreduce.lib.output.SequenceFileOutputFormat;
import org.apache.mahout.clustering.Cluster;
import org.apache.mahout.clustering.classify.ClusterClassifier;
import org.apache.mahout.clustering.iterator.ClusterIterator;
import org.apache.mahout.clustering.iterator.ClusteringPolicy;
import org.apache.mahout.clustering.kmeans.KMeansConfigKeys;
import org.apache.mahout.common.ClassUtils;
import org.apache.mahout.common.distance.DistanceMeasure;
import org.apache.mahout.math.DenseVector;
import org.apache.mahout.math.MatrixSlice;
import org.apache.mahout.math.Vector;
import org.apache.mahout.math.VectorWritable;
import org.apache.mahout.math.hadoop.DistributedRowMatrix;
import org.apache.mahout.math.map.OpenHashMap;

public class ElkanKMeansJob {

	public static int run(Path input, Path output, Configuration conf, int iteration) {
		try {
			Job job = new Job(conf, "Elkan KMeans job.");

			if (iteration==1)
				job.setMapperClass(ElkanVectorMapper.class);
			else
				job.setMapperClass(ElkanStep1Mapper.class);
			job.setMapOutputKeyClass(Text.class);
			job.setMapOutputValueClass(ElkanVectorWritable.class);

			job.setReducerClass(Reducer.class);
			job.setOutputKeyClass(Text.class);
			job.setOutputValueClass(ElkanVectorWritable.class);

			job.setOutputFormatClass(SequenceFileOutputFormat.class);
			FileOutputFormat.setOutputPath(job, output);

			job.setInputFormatClass(SequenceFileInputFormat.class);
			FileInputFormat.setInputPaths(job, input);

			job.setJarByClass(ElkanKMeansJob.class);

			job.waitForCompletion(true);
		} catch (Exception e) {
			System.err.println(e.getMessage());
			e.printStackTrace(System.err);
			return 1;
		}

		return 0;
	}

	public static class ElkanVectorMapper
			extends
			Mapper<WritableComparable<?>, VectorWritable, WritableComparable<?>, ElkanVectorWritable> {

		private ClusterClassifier classifier;

		private ClusteringPolicy policy;
		
		private DistanceMeasure measure;
		
		private Vector medianDistanceClusters;		
		
		private OpenHashMap<Integer,Vector> clusterDistanceMatrix;

		@Override
		protected void setup(Context context) throws IOException,
				InterruptedException {
			Configuration conf = context.getConfiguration();
			String measureClass = conf.get(KMeansConfigKeys.DISTANCE_MEASURE_KEY);
		    measure = ClassUtils.instantiateAs(measureClass, DistanceMeasure.class);
			String priorClustersPath = conf.get(ClusterIterator.PRIOR_PATH_KEY);
			classifier = new ClusterClassifier();
			classifier.readFromSeqFiles(conf, new Path(priorClustersPath));
			policy = classifier.getPolicy();
			policy.update(classifier);
			
			int i=0;
			List<Cluster> models=classifier.getModels();
			medianDistanceClusters=new DenseVector(models.size());
			
			for (Cluster model:models)
			{
				Vector centerDistances=new DenseVector(models.size());
				int j=0;
				for (Cluster oth_model:models)
				{					
					centerDistances.setQuick(j, measure.distance(model.getCenter(), oth_model.getCenter()));
					j++;
				}
				
				double sCenter=centerDistances.minValue()/2;
				medianDistanceClusters.setQuick(i, sCenter);
				i++;
			}
			
			clusterDistanceMatrix=new OpenHashMap<Integer, Vector>(models.size());			
			Path clusterDistanceMatrixPath=new Path(conf.get(ElkanIterator.CENTROID_DISTANCES_PATH_KEY));
			Path clusterDistanceMatrixOutput=new Path(conf.get(ElkanIterator.CENTROID_DISTANCES_PATH_KEY)+"/output");
			DistributedRowMatrix rowMatrix=new DistributedRowMatrix(clusterDistanceMatrixPath,clusterDistanceMatrixOutput,
					models.size(),models.size());
			rowMatrix.setConf(conf);
			Iterator<MatrixSlice> it=rowMatrix.iterator();
			while (it.hasNext())
			{
				MatrixSlice slice=it.next();
				clusterDistanceMatrix.put(slice.index(),slice.vector());
			}
			super.setup(context);
		}

		@Override
		protected void map(WritableComparable<?> key, VectorWritable value,
				Context context) throws IOException, InterruptedException {
			Vector originVector=value.get();
			int i=0;
			Vector probabilities = new DenseVector(classifier.getModels().size());
			for (Cluster model:classifier.getModels())
			{
				probabilities.setQuick(i, measure.distance(originVector, model.getCenter()));
				i++;
			}
			
			ElkanVector elkanVector=new ElkanVector();
			elkanVector.setDelegate(originVector);
			elkanVector.setLowerLimits(probabilities);
			elkanVector.setClusterId( probabilities.minValueIndex());
			elkanVector.setCalculateDistance(true);
			elkanVector.setUpperLimit(probabilities.minValue());
			ElkanSteps.updateVectorCentroid(elkanVector, classifier, medianDistanceClusters, clusterDistanceMatrix, measure);
			context.write(key, new ElkanVectorWritable(elkanVector));
		}

	}
}
